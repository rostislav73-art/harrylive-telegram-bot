import os
import openai
import requests
from flask import Flask, request
from dotenv import load_dotenv

# –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ .env —Ñ–∞–π–ª–∞
load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")
API_URL = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"

app = Flask(__name__)

# –ù–æ–≤–∏—è—Ç –º–µ—Ç–æ–¥ –∑–∞ Chat Completion
def generate_reply(message_text):
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": message_text}
        ]
    )
    return response.choices[0].message.content

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ—Ç–æ —Ä–∞–±–æ—Ç–∏
@app.route("/", methods=["GET"])
def index():
    return "Bot is running."

# Webhook endpoint
@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.get_json()
    print("üì• Incoming:", data)

    try:
        message = data["message"]
        chat_id = message["chat"]["id"]
        text = message.get("text", "")

        reply = generate_reply(text)

        payload = {
            "chat_id": chat_id,
            "text": reply
        }

        r = requests.post(API_URL, json=payload)
        print("üì§ Sent:", r.status_code, r.text)

    except Exception as e:
        print("‚ùå Error:", e)

    return {"ok": True}
